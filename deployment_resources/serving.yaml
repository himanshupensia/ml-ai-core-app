apiVersion: ai.sap.com/v1alpha1
kind: ServingTemplate
metadata:
  name: ml-inference-template
  annotations:
    scenarios.ai.sap.com/description: "Simple Iris Random Forest"
    scenarios.ai.sap.com/name: "my-ml-scenario"
    executables.ai.sap.com/description: "Inference server for Iris model"
    executables.ai.sap.com/name: "my-ml-executable"
  labels:
    scenarios.ai.sap.com/id: "my-ml-scenario"
    ai.sap.com/version: "1.0.0"
spec:
  inputs: []
  template: 
    apiVersion: serving.kserve.io/v1beta1
    metadata:
      annotations:
        autoscaling.knative.dev/minScale: "1"
      labels:
        ai.sap.com/resourcePlan: "starter"
    spec:
      predictor:
        containers:
        - name: kserve-container
          # REPLACE 'YOUR_DOCKER_USER' with your actual Docker Hub username
          image: "docker.io/himanshupensia/ml-inference:v1" 
          ports:
          - containerPort: 9001
            protocol: "TCP"